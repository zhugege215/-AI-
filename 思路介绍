比赛介绍：
该比赛以工业半导体制造为背景，根据提供的工序数据，预测生产出来的半导体质量。其中半导体质量用Value来表征，训练集有800数据，测试a有
300数据，测试集b有412数据，共有5952个特征，以mse为评定标准。
解题思路：
根据题目背景，该题目为典型的回归问题，题目难点为特征太多，样本太少。所以重点是进行数据清洗和特征工程，而由于样本较少，不同测试集的mse
波动比较大（样本数目决定）。根据分析和探索，最终的解决思路如下：
（1）数据初步观察
训练集、测试集a和测试集b不是同分布的。训练集的样本范围是NH0995-NH1942，测试集a的样本范围是NH1943-NH1992和NH0016-NH0463，测试集
b的样本范围是NH0464-NH0994。主要测试集样本的范围发生了一次突变，所以造成很多特征的取值也发生突变，这些特征是数据清理的重点。
（2）异常样本删除。
根据分析数据发现，样本NH1835的Value值非常小判定为异常，而NH1543、NH1544、NH1545、NH1546、NH1573、NH1574这6个样本同一个id有两个
样本，而且所有的属性和Value值全部一样，也判定为异常。所以删除训练集中的NH1543、NH1544、NH1545、NH1546、NH1573、NH1574和NH1835
7个样本。
（3）异常特征处理。
    1）删除训练集中全空的特征。
    2）删除训练集中方差为0的特征，即改特征的取值在训练集中全一样。
    3）删除测试集中缺失值很多的特征。根据分析之后，测试集a中缺失值249以上和测试集b中缺失值249以上的特征是一样的，所以决定阈值定位249。
    4）删除训练集和测试集中分布差距较大的特征，方法是如果某特征在测试集中有较多样本的取值超出了训练集中所有样本取值的范围，那么认定为
       异常，具体有多少个超出算异常根据实际情况调节，在此次比赛中选择50-60。
（4）去线性化处理。
如果多个特征之间存在很强的线性关系，那么只保留其中的一个。因为如果多个特征的线性关系很强，那么其中的任何一个特征都可以提供所有特征的信
息量。根据具体的调节，如果一个特征和多个特征的线性相关系数大于0.97或小于-0.97，则只保留该特征。
（5）xgboost特征选择。
根据xgboost中的feature_importance对特征进行重要性摆明，选择排名靠前的特征。
（6）gbdt模型训练。
使用gbdt模型进行训练和调参，调参使用sklearn的GridSearchCV库，其中学习率和训练轮数一起调整，树的最大深度单独调整。
说明：比赛开始阶段，需要提交测试集a的预测结果，所以使用原始训练集训练。在比赛后期需要提交测试集b预测结果，并且作为最终成绩。在对测试
集b进行预测时，测试集a的答案已经给出，所以为了增加训练的样本，决定将测试集a加入到训练集中组成新的训练集。在组成新的训练集的过程中思路
发生了一次改变，开始的思路是在xgboost进行特征选择和gbdt模型训练时将训练集和测试集a合并在一起，前边的异常特征处理中分别计算出测试集a
和测试集b中分布差距比较大的特征进行删除，但是这样做的坏处是去线性化处理时只考虑了原始训练集的线性关系，而后边是根据训练集和测试集a合并
的新训练集进行的特征选择和模型拟合，这是不合理的。后边的思路是在最开始就将训练集和测试集a合并在一起，然后进行异常特征处理等操作，但是
在前边处理过程中发现有一些特征在测试集a中有很多样本超出（甚至远远超出）原始训练集的范围，判定这些特征是异常特征，所以在合并之前先计算
出这些特征，在合并之后立即将它们删除，再做后续处理。